{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with CIFAR-10\n",
    "\n",
    "From the [website](https://www.cs.toronto.edu/~kriz/cifar.html): \"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\"\n",
    "\n",
    "Let's try some stuff out. \n",
    "\n",
    "1. Dimensionality reduction (PCA)\n",
    "\n",
    "2. K-means clustering (perhaps in different dimensions)\n",
    "\n",
    "3. Siple least squares regression with one-hot output vectors\n",
    "\n",
    "4. Simple feedforward NN (Dropout, L2 Regularization)\n",
    "\n",
    "5. A convolutional neural network. I expect this to have the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data\n",
    "\n",
    "This was blissfully easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python\n",
    "\n",
    "#Script source: \n",
    "#https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "#useful sources\n",
    "#http://parneetk.github.io/blog/cnn-cifar10/\n",
    "\n",
    "import pickle\n",
    "import numpy as np \n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_cases_per_batch': 10000,\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
    "batch_2 = unpickle('cifar-10-batches-py/data_batch_2')\n",
    "batch_3 = unpickle('cifar-10-batches-py/data_batch_3')\n",
    "batch_4 = unpickle('cifar-10-batches-py/data_batch_4')\n",
    "batch_5 = unpickle('cifar-10-batches-py/data_batch_5')\n",
    "test_batch = unpickle('cifar-10-batches-py/test_batch')\n",
    "\n",
    "meta_data = unpickle('cifar-10-batches-py/batches.meta')\n",
    "meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = [batch_1, batch_2, batch_3, batch_4, batch_5]\n",
    "\n",
    "all_training_features = np.vstack((batch_1[b'data'], batch_2[b'data'], \n",
    "                               batch_3[b'data'], batch_4[b'data'], batch_5[b'data']))\n",
    "all_training_labels = np.hstack((batch_1[b'labels'], batch_2[b'labels'], \n",
    "                               batch_3[b'labels'], batch_4[b'labels'], batch_5[b'labels']))\n",
    "\n",
    "test_features = test_batch[b'data']\n",
    "test_labels = test_batch[b'labels']\n",
    "\n",
    "'''Standardize the image pixel values, which are normally in [0, 255].'''\n",
    "\n",
    "test_features = test_features/255\n",
    "all_training_features = all_training_features/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Some useful functions.'''\n",
    "\n",
    "label_names = meta_data[b'label_names']\n",
    "\n",
    "'''Returns the accuracy rate of a prediction against the true labels.\n",
    "Assumes both prediction and true_labels contain integers only, although'''\n",
    "def accuracy(prediction, true_labels): \n",
    "    assert len(prediction) == len(true_labels), 'Mismatched prediction and label set'\n",
    "    prediction = np.int_(np.rint(np.array(prediction))) #round to nearest integer and cast to integer type\n",
    "\n",
    "    num_accurate = 0\n",
    "    for i in range(len(prediction)): \n",
    "        if(prediction[i] == true_labels[i]): \n",
    "            num_accurate += 1 \n",
    "    return (num_accurate/len(prediction))\n",
    "\n",
    "'''Takes a label value (an integer between 1 and 10) and returns the corresponding\n",
    "string which the label corresponds to. Example: 3 --> bird '''\n",
    "def number_to_name(num): \n",
    "    assert type(num) == int, '{} is not an integer'.format(num)\n",
    "    assert num in [x for x in range(1, 11)], '{} is not between 1 and 10'.format(num)\n",
    "    return label_names[num - 1].decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 59,  43,  50, ..., 140,  84,  72], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1[b'data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares\n",
    "\n",
    "The most naive approach I know of is to model the problem as a least-squares optimization problem. Let $X$ be the feature matrix, where each row has 3072 entries corresponding to pixel values. Let $y$ be the label-vector, where each entry is the label for the corresponding row entry in $X$. Then the goal is to find **weight vector** $w$ such that $$Xw \\approx y$$\n",
    "\n",
    "The analytic solution to least squares is \n",
    "\n",
    "$$w = (X^T X)^{-1} X^{T}y$$\n",
    "\n",
    "## Implementing on One Batch\n",
    "\n",
    "To start, I'll implement the solution on one batch of data and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = batch_1[b'data']\n",
    "label_vector = batch_1[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes about 10 seconds to run\n",
    "\n",
    "weight = np.linalg.lstsq(feature_matrix, label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_vector = weight[0]\n",
    "residuals = weight[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.rint(feature_matrix @ weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1516"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(prediction, label_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oof. We get an accuracy of 15.2%, and that's on the training set! I'll bet it's much worse on a fresh batch.\n",
    "\n",
    "Let's use the same weight vector as before, but a new batch of image features and labels as a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1068"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_2 = batch_2[b'data']\n",
    "labels_2 = batch_2[b'labels']\n",
    "\n",
    "prediction_2 = np.rint(feature_matrix_2 @ weight_vector)\n",
    "\n",
    "accuracy(prediction_2, labels_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the accuracy is even lower - a poor showing at 10.7%.\n",
    "\n",
    "## Training on all 5 Batches\n",
    "\n",
    "Let's try training on all 5 batches. Perhaps this will just overfit, but for sheer curiosity it's worth trying out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_all_batches = np.linalg.lstsq(all_training_features, all_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11742"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_vector_all_batches = weight_all_batches[0]\n",
    "\n",
    "all_batch_prediction = all_training_features @ weight_vector_all_batches\n",
    "accuracy(all_batch_prediction, all_training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so a training accuracy of 11.7% as opposed to the earlier 15.2% for one batch. What about test error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1148"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_batch_test_prediction = test_features @ weight_vector_all_batches\n",
    "accuracy(all_batch_test_prediction, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a test accuracy of 11.5%. Nothing too exciting here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets\n",
    "\n",
    "Let's bring out the big guns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
